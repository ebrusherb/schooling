\documentclass{article}
%\documentclass[aps, twocolumn, tightenlines,amscd,amsmath,amssymb,verbatim]{revtex4}
\usepackage{latexsym}
\usepackage{amssymb,amsmath}
\usepackage{custom2}
\usepackage{graphicx} % for figures
\usepackage{epstopdf} % so can use EPS or PDF figures
%\usepackage{subfig}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{url}
\usepackage{amssymb,amsfonts}
\usepackage[all,arc]{xy}
\usepackage{enumerate}
\usepackage{mathrsfs}
\usepackage{booktabs}
\usepackage[pdftex]{hyperref}
\usepackage{lscape}
\captionsetup{justification=RaggedRight, singlelinecheck=false}
\newcommand{\ra}[1]{\renewcommand{\arraystretch}{#1}}
\newcommand{\argmax}{\text{argmax}}
\newcommand{\Tr}{\text{Tr}}
\newcommand{\z}{\mathscr{Z}}
%\newtheorem{claim}{Claim}

\addtolength{\evensidemargin}{-.5in}
\addtolength{\oddsidemargin}{-.5in}
\addtolength{\textwidth}{1.4in}
\addtolength{\textheight}{1.4in}
\addtolength{\topmargin}{-.5in}

\pagestyle{empty}

\begin{document}


\begin{center}
{\bf \LARGE{Evolution of Information Gathering Strategies}}
\vspace{10pt}
\\ Eleanor Brush
\\ October 31, 2014
\end{center}

\tableofcontents

\section{Abstract}
Birds in flocks, like animals in many types of social groups, can use their peers to learn about the environment and update their opinions about where to move in that environment.  Previous work on starlings has measured the number of other birds an individuals pays attention to and shown that this number of ``neighbors" leads to a social network that is conducive to the whole flock reaching consensus.  It is unclear, however, why an individual would change its behavior, i.e. the number of neighbors it learns from, to achieve this outcome.  Individual birds should optimize how well they learn about the environment. There are (at least) two features of the environment that are important to an individual bird's fitness---the location of a predator and the location of resources---and it can try to learn about these from its peers. In this work, we identify the optimal strategies for birds under selection pressure dictated by these types of information and explore the relationship between the robustness measure and the correlation length of the flock, a measure commonly used to describe how close a flock's structure is to criticality.


\section{Model }
\subsection{Learning dynamics }
An individual's opinion changes with a probability that depends on its social interactions and the strength of the environmental stimulus. Specifically, an individual's opinion $\sigma_i$ can be either $1$ or $-1$ and $\sigma_i$ switches with probability $w_i(\sigma_i)=\frac{1}{2}(-\sigma_i\sum_jA_{ij}\sigma_j )(1-\beta_i\sigma_i)$ where $A_{ij}$ indicates the strength of the connection from $j$ to $i$ and $\beta_i$ indicates the strength of the environmental stimulus perceived by $i$.  The stochastic dynamics of the opinions can be written down with a master equation \cite{Glauber:1963fk}.  The vector $\vec{v}(t)$ of expected values, $q_i(t)=\langle \sigma_i(t)\rangle$, satisfies the following differential equations: \cite{Glauber:1963fk}
\begin{equation*}
\frac{d\vec{v}}{dt}=M\vec{v}+\vec{\beta}^T(\vec{1}-\vec{v}).
\end{equation*}
We simplify this by writing $\frac{d\vec{v}}{dt}=A\vec{v}+\vec{\beta}^T\vec{1}$, where $A=M-B$ and $B$ is a diagonal matrix with the values of $\vec{\beta}$ along the diagonal. In the absence of the environmental signal, there is no trend in the dynamics. In the presence of the environmental signal, however, those individuals who perceive the signal will be more likely to switch to having an opinion of $1$ so their expected value will increase, and consequently so will the values of the those paying attention to the informed individuals. Thus, having a higher expected value can be interpreted as having more information about the information and having a lower expected value can be interpreted as having less information.

\subsection{Individual-level fitness }
To find the optimal strategies from the individuals' perspectives, we need a measure of individual-level fitness, which we define as follows. Each individual has a strategy that determines how many other individuals he pays attention to, $n_i=\sum_{j\neq i}{\bf I}(A_{ij}\neq 0)$.  We distribute the individuals randomly in space.  Each individual then pays attention to its $n_i$ nearest neighbors.  One individual is chosen to be a receiver; it and all those individuals within a radius $r$ of the receiver perceive an external signal of strength $\beta$.  We find the expected opinion of each individual $q_i$ after a period of time $T$.  We refer to each such set of random positions and receiver as a signaling event. 

We consider two types of signals: predators and food.  If the signal is information that a predator is present, we assume that whichever individual is least aware of the signal will be predated, i.e. the individual $i$ such that $q_i$ is lowest.  We therefore find, over many signaling events, the probability that an individual will be eaten and an individual's fitness is given by the probability of surviving, i.e. $1$ minus the probability of being predated.  If the signal is information that resources are available, we assume that whichever individual is most aware of the signal will get access to the resource, i.e. the individual $i$ such that $q_i$ is highest. In this case, fitness is proportional to the probability of being the first to reach the resources. 

\subsection{Group-level performance }
We consider two group-level properties that indicate how cohesive the group is.  The first property is $\mathscr{H}_2$ robustness, as used in \cite{Young:2010fk,Young:2013kx}. This is a measure of the robustness of the consensus state in which all birds have the same opinion to noise at equilibrium, as used in (see Appendix Sec. \ref{H2}). The second property is the correlation length of the flock. This is the distance at which the average correlations between birds changes from positive to negative, i.e. the distance over which birds' opinions tend to be positively correlated with each other (see Appendix Sec \ref{corr}).

\subsection{Optimization methods }
To understand what strategies we might expect to find, we are interested in identifying the optimal strategies.  We does this in two ways.  First, using the framework of adaptive dynamics in finite populations, we identify the evolutionarily stable strategy.  This framework assumes that there is a homogeneous population into which a mutant individual tries to invade.  If strategies change on a learning rather than an evolutionary timescale, or if there is just a lot of variation in the population, we might expect individuals to try to optimize their strategies in the context of a heterogeneous population.  This is our second method of optimization. Given a random set of initial strategies over the group, we allow each bird to choose the strategy that would be best given the rest of the strategies being used and repeat this process until the birds reach an equilibrium set of strategies. We repeat this over many initial sets of strategies to find average properties of this optimization process.

\section{Results }

\subsection{ESS strategies }
Surprisingly, even without imposing costs on paying attention to more neighbors, paying attention to the whole flock is not usually the best strategy. The ESS strategy of the number of neighbors to pay attention strongly depends on which selection pressure is being applied.  If a focal bird pays attention to many others, its opinion will be similar to theirs. This will prevent it from being the most informed and hence the first to locate resources. Thus, the uninvadable strategy is to pay attention to few neighbors when selection is due to knowledge about resources. On the other hand, having many neighbors will prevent the focal bird from being the least informed and thus the most likely to be eaten.  Thus, the uninvadable strategy is to pay attention to many neighbors when selection is due to knowledge about predators. Figure \ref{ESS} shows the ESS strategy when selection is due to knowledge about resources is always lower than the ESS strategy when selection is due to knowledge about predators (Figure \ref{ESS}).

The ESS strategies when selection is due to knowledge about predators show two interesting features. First, there are many parameters for which there are multiple ESS strategies. It might seem that if a strategy outperforms all others when it is the resident strategy, it should also outperform other strategies as an invader. However, when there are multiple ESS strategies, if we take any two of those ESS strategies, each is uninvadable by the other. This indicates how important the social environment set by the resident strategy is. The resident strategy essentially sets a level of background noise. As an example, consider the strategies of having sixteen or seventeen neighbors when the radius of the signal is $r=0.1$. Figure \ref{ESS} shows how the probability of being predated for each of these invasion scenarios depends on the number of birds in the group and the number of informed neighbors the invader has.  A bird with seventeen neighbors will have more uninformed neighbors than one with sixteen neighbors and thus will have less information itself. This poor information is  costly when the resident strategy is to have sixteen neighbors since the residents will have less noisy information, which prevents an mutant with seventeen neighbors to invade. Figure \ref{ESS} shows that by paying attention to more uninformed neighbors this mutant is likely to be eaten when there are many truly informed birds. However, having less noisy information does not allow a sixteen neighbor mutant to invade a seventeen neighbor group since, regardless of the number of uninformed neighbors the invader has, the background level of noise is much higher in a group all of whom have more uninformed neighbors. The sixteen neighbor mutant also pays a cost by being less likely to pay attention to the right neighbors when there are very few truly informed birds.  Figure \ref{ESS} shows that by being less likely to pay attention to the right neighbors this mutant is likely to be eaten when there are few truly informed birds.

These opposing forces caused by the costs of paying attention to more uninformed neighbors and the costs of not paying attention to informed neighbors also explains the second feature of the ESS strategies: they are non-monotonic with respect to the the radius of the signal, i.e. how public the signal is (Figure \ref{ESS}). Figure \ref{ESS} shows that there are essentially three categories of radii: When the radius is low, the signal is private, with only a few birds having true information. When the radius is intermediate, the signal is public, with many birds having true information. When the radius is high, the signal is universal, with essentially all birds in the flock having true information. When the signal is private, paying attention to too few birds is costly because with more neighbors it is more likely to have a truly informed neighbor, but paying attention to too many uninformed birds can also be costly. This leads to a high but not maximal ESS strategy. When the signal is public, the costs of paying attention to uninformed birds are reduced and the ESS strategy increases to become as high as possible. When the signal is universal, not paying attention to informed birds does not impose a cost. Additionally, in a group in which the residents pay attention to all of their neighbors, any mutant strategy can get just as much information by paying attention to fewer neighbors so the maximal strategy is no longer an ESS (Figure \ref{ESS}).

\subsection{Learned strategies }
The equilibrium strategies when the individuals are allowed to learn are similar to the ESS strategies: learned strategies when selection is due to predation are always higher than learned strategies when selection is due to resources (Figure \ref{greedyopt}). Surprisingly, even when the group starts with heterogeneous strategies, they often reach a homogeneous equilibrium. Under selection due to predation, the $\mathscr{H}_2$ robustness and correlation length of the flock tend to decrease, whereas under selection due to resources, $\mathscr{H}_2$ robustness is relatively constant and correlation length tends to increase (Figure \ref{greedyopt}).

\subsection{Relationship between group properties }
Figure \ref{greedyopt} shows that there is a relationship between two group properties: the $\mathscr{H}_2$ norm and the correlation length of the flock.

\section{Discussion}
explore vs. exploit 
risk aversion vs. risk tolerance

expect single ESS strategies but social information depends on the social environment set by the resident strategy
expect ESS strategies to decrease as the signal becomes more public, but we find the opposite

\section{Figures }
\begin{figure}[ht]
\includegraphics[width=6.83in]{/Users/eleanorbrush/Desktop/ESSfigure.pdf}
\caption{\label{ESS} The ESS number of neighbors is always higher if selection is due to predation than due to resources. When selection is due to predation, there can be multiple ESS strategies, which are a non-monotonic function of the radius of the signal. In (a), we show the (possibly multiple) ESS strategies as a function of the radius of the signal. In (b) we show the probability of there being a given number of informed birds for signals with different radii. In (c) and (d), each heat map shows the probability that an invader is eaten as a function of the number of informed birds in the flock on the horizontal axis and the number of informed neighbors the invader has on the vertical axis. In (c), the resident strategy is to have $16$ neighbors and the invader strategy is to have $17$ neighbors. In (d), the resident strategy is to have $17$ neighbors and the invader strategy is to have $16$ neighbors. Parameters:  in all panels $\beta=1$, $T=1$, in (c) and (d) $r=0.1$. 
}
\end{figure}

\begin{figure}[ht]
\includegraphics[width=6.83in]{/Users/eleanorbrush/Desktop/greedyoptneighbors.pdf}
\caption{\label{greedyopt} When the birds choose the optimal number of neighbors, given the strategies the rest of the flock are using, they settle on higher strategies when selection is due to predation than when selection is due to resources. Under selection due to predation, the $\mathscr{H}_2$ robustness and correlation length of the flock tend to decrease, whereas under selection due to resources, $\mathscr{H}_2$ robustness is relatively constant and correlation length tends to increase. The upper row shows results from implementing selection based to predation and the lower row shows results from implementing selection based on resources. In each panel, the x-axis represents the number of times the birds are allowed to choose optimal strategies. The first column shows one example of how the birds' strategies change over time. The second column shows, for many initial conditions, how the $\mathscr{H}_2$ robustness changes over time. The third column shows, for many initial conditions, how the correlation length changes over time. Parameters:  $\beta=1$, $r=.1$, $T=1$. 
}
\end{figure}

\newpage
\section{Appendix}
\subsection{H2 Norm \label{H2}} 

\ Let $y$ represent the distance between the vector of opinions and consensus, i.e.
$y=QxQ^T,$
where $Q\in\R^{n-1\times n}$ is such that $Q\vec{1}=0$ , $QQ^T=I_{n-1}$, and $Q^TQ=I_n-\frac{1}{n}\vec{1}\times\vec{1}^T$.   
Then 
\begin{equation}
\dot{y}(t)=-\overline{L}y(t)+Q\xi(t) \notag
\end{equation}
where $\overline{L}=QLQ^T$.  As shown in \cite{Young:2010fk}, if $\Sigma_y(t)=\E[y(t)y(t)^T]$,  $\Sigma_y$ at equilibrium solves
\begin{equation} 0=-\overline{L}\Sigma_y-\Sigma_y\overline{L}^T+D. \label{h2norm}
\end{equation}
\begin{align*}
\mathscr{H}_2&=\sqrt{\Tr(\Sigma_y)}
\\\mathscr{H}_2 \text{ robustness} &=\frac{1}{\mathscr{H}_2}
\end{align*}

\subsection{Calculating correlations \label{corr}}
The following is derived from the work in \cite{Bialek:2013fk}.
\begin{align*}
H(\vec{v})&=-\vec{v}^TA\vec{v}-\vec{\beta}^T\vec{v}
%\\&=\vec{v}A\vec{v}-\vec{\beta}^T\vec{v}+\vec{\beta}^T\vec{1}
\end{align*}
Define $V=\sum_kv_k/N$ and $\vec{y}=(\vec{v}-V\vec{1})/V$.  Then $\vec{v}=V(\vec{1}+\vec{y})$.  
\begin{align*}
H(\vec{y},V)&=-V^2(\vec{1}^T+\vec{y}^T)A(\vec{1}+\vec{y})-\vec{\beta}^TV(\vec{1}+\vec{y})
\\&=-V^2(\vec{1}^T+\vec{y}^T)A\vec{y}-V\vec{\beta}^T\vec{y}-V\vec{\beta}^T\vec{1} \text{ since $A\vec{1}=\vec{0}$}
\\&=-V^2\vec{y}^TA\vec{y}+(-V^2\vec{1}^TA-V\vec{\beta}^T)\vec{y}-V\vec{\beta}^T\vec{1}
\end{align*}
Define $Q\in M_{N-1,N}$ that rotates an $N$-vector away from the consensus vector and define $\vec{z}=Q\vec{y}$ so that $\vec{y}=Q^T\vec{z}$ since $\sum_ky_k=0$.
\begin{align*}
H(\vec{z},V)&=-V^2\vec{z}^TQAQ^T\vec{z}+(-V^2\vec{1}^TAQ^T-V\vec{\beta}^TQ^T)\vec{z}-V\vec{\beta}^T\vec{1}
\\&=V^2\vec{z}^TP\vec{z}+(-V^2\vec{\sigma}_1^T-V\vec{\sigma}_2^T)\vec{z}-V\vec{\beta}^T\vec{1}
\\ \Rightarrow P(\vec{z},V)&=\frac{1}{\z}\exp\left(-V^2\vec{z}^TP\vec{z}+(V^2\vec{\sigma}_1^T+V\vec{\sigma}_2^T)\vec{z}+V\vec{\beta}^T\vec{1}\right)
\end{align*}
where $P=-QAQ^T$, $\vec{\sigma}_1=QA^T\vec{1}$, and $\vec{\sigma}_2=Q\vec{\beta}$.


\begin{fact}
\begin{align*}
\int\exp\left(-\frac{1}{2}\vec{z}^TP\vec{z}+\vec{\sigma}^T\vec{z}\right)d^{N-1}z&=\sqrt{\frac{(2\pi)^{N-1}}{\det P}}\exp\left(-\frac{1}{2}\vec{\sigma}^TP^{-1}\vec{\sigma}\right)
\\\Rightarrow \int\exp\left(-\vec{z}^TP\vec{z}+\vec{\sigma}^T\vec{z}\right)d^{N-1}z&=\sqrt{\frac{(2\pi)^{N-1}}{2^{N-1}\det P}}\exp\left(-\frac{1}{4}\vec{\sigma}^TP^{-1}\vec{\sigma}\right)
\\&=\sqrt{\pi^{N-1}}\sqrt{\frac{1}{\det P}}\exp\left(-\frac{1}{4}\vec{\sigma}^TP^{-1}\vec{\sigma}\right)
\end{align*}
\end{fact}

\begin{align*}
\z&=\int_{-\infty}^\infty\int_{\R^{N-1}}\exp\left(V^2\vec{z}^TP\vec{z}+(V^2\vec{\sigma}_1^T+V\vec{\sigma}_2^T)\vec{z}+V\vec{\beta}^T\vec{1}\right)d^NzdV
\\&=\int_{-\infty}^\infty \exp(V\vec{\beta}^T\vec{1})\int_{\R^{N-1}}\exp\left(V^2\vec{z}^TP\vec{z}+(V^2\vec{\sigma}_1^T+V\vec{\sigma}_2^T)\vec{z}\right)d^NzdV
\\&=\sqrt{\pi^{N-1}}\int_{-\infty}^\infty\exp(V\vec{\beta}^T\vec{1})\times\left(\sqrt{\frac{1}{V^{2(N-1)}\det{P}}}\right)\exp\left(-\frac{1}{4}\vec{\sigma}_1^TP^{-1}\vec{\sigma}_1\right)\exp\left(-\frac{1}{4V}\vec{\sigma}_2^TP^{-1}\vec{\sigma}_2\right)dV
\\&=\sqrt{\pi^{N-1}}\sqrt{\frac{1}{\det PP}}\exp\left(-\frac{1}{4}\vec{\sigma}_1^TP^{-1}\vec{\sigma}_1\right)\int_{-\infty}^\infty\exp(V\vec{\beta}^T\vec{1})\times\left(\sqrt{\frac{1}{V^{2(N-1)}}}\right)\exp\left(-\frac{1}{4V}\vec{\sigma}_2^TP^{-1}\vec{\sigma}_2\right)dV
\\&=\sqrt{\pi^{N-1}}\sqrt{\frac{1}{\det P}}\exp\left(-\frac{1}{4}\vec{\sigma}_1^TP^{-1}\vec{\sigma}_1\right)\int_{-\infty}^\infty\frac{1}{V^{(N-1)}}\exp\left(V\vec{\beta}^T\vec{1}-\frac{1}{4V}\vec{\sigma}_2^TP^{-1}\vec{\sigma}_2\right)dV
\\&=\sqrt{\pi^{N-1}}\sqrt{\frac{1}{\Pi_a\lambda_a}}\exp\left(-\frac{1}{4}\vec{\sigma}_1^TP^{-1}\vec{\sigma}_1\right)\int_{-\infty}^\infty\frac{1}{V^{(N-1)}}\exp\left(V\vec{\beta}^T\vec{1}-\frac{1}{4V}\vec{\sigma}_2^TP^{-1}\vec{\sigma}_2\right)dV 
\\&\text{ where $\lambda_a$ are the eigenvalues of $P$}
\\ \Rightarrow -\log(\z)&=\text{constants}+\frac{1}{2}\sum_a\log(\lambda_a)+\frac{1}{4}\vec{\sigma}_1^TP^{-1}\vec{\sigma_1}-\log(f(P))
\end{align*}

where $f(P)=\int_{-\infty}^\infty\frac{1}{V^{(N-1)}}\exp\left(V\vec{\beta}^T\vec{1}-\frac{1}{4V}\vec{\sigma}_2^TP^{-1}\vec{\sigma}_2\right)dV $.

\begin{align*}
\Rightarrow\frac{\partial -\log(\z)}{\partial P_{ij}}&=\frac{1}{2}\sum_a\frac{w_iw_j}{\lambda_a}+\frac{1}{4}\sum_{kl}\sigma_{1k}P^{-1}_{ki}P^{-1}_{jl}\sigma_{1l}-\frac{\partial \log f}{\partial P_{ij}}
\\\Rightarrow\frac{\partial -\log(\z)}{\partial P_{ij}}&=\frac{1}{2}\sum_a\frac{w_iw_j}{\lambda_a}+\frac{1}{4}\sum_{kl}\sigma_{1k}P^{-1}{ki}P^{-1}_{jl}\sigma_{1l}-\frac{1}{f}\frac{\partial f}{\partial P_{ij}}
\end{align*}

\begin{align*}
\frac{\partial f}{\partial P_{ij}}&=\int_{-\infty}^\infty\frac{1}{V^{(N-1)}}\exp\left(V\vec{\beta}^T\vec{1}-\frac{1}{4V}\vec{\sigma}_2^TP^{-1}\vec{\sigma}_2\right)\left(-\frac{1}{4V}\sum_{kl}\sigma_{2k}P^{-1}_{ki}P^{-1}_{jl}\sigma_{2l}\right)dV
\\&=\left(-\frac{1}{4}\sum_{kl}\sigma_{2k}P^{-1}_{ki}P^{-1}_{jl}\sigma_{2l}\right)\int_{-\infty}^\infty\frac{1}{V^{(N)}}\exp\left(V\vec{\beta}^T\vec{1}-\frac{1}{4V}\vec{\sigma}_2^TP^{-1}\vec{\sigma}_2\right)dV
\end{align*}

\small{
\begin{align*}
\Rightarrow\langle z_iz_j\rangle &=\frac{1}{2}\sum_a\frac{w_iw_j}{\lambda_a}+\frac{1}{4}\sum_{kl}\sigma_{1k}P^{-1}{ki}P^{-1}_{jl}\sigma_{1l}+\left(\frac{1}{4}\sum_{kl}\sigma_{2k}P^{-1}_{ki}P^{-1}_{jl}\sigma_{2l}\right)\frac{\int_{-\infty}^\infty\frac{1}{V^{(N)}}\exp\left(V\vec{\beta}^T\vec{1}-\frac{1}{4V}\vec{\sigma}_2^TP^{-1}\vec{\sigma}_2\right)dV}{\int_{-\infty}^\infty\frac{1}{V^{(N-1)}}\exp\left(V\vec{\beta}^T\vec{1}-\frac{1}{4V}\vec{\sigma}_2^TP^{-1}\vec{\sigma}_2\right)dV}
\end{align*}}


\subsection{Equivalence of dynamics and Hamiltonian }
\begin{claim}
If $H(\vec{v})=-\vec{v}^TA\vec{v}-\vec{\beta}^T\vec{v}$ and $\frac{d\vec{v}}{dt}=A\vec{v}+\vec{\beta}$ then $\nabla H\cdot \frac{d\vec{v}}{dt}\leq 0$.
\end{claim}
\begin{pf}
\begin{align*}
H(\vec{v})&=-\sum_{ij}A_{ij}v_iv_j-\sum_i\beta_iv_i
\\\Rightarrow\frac{\partial H}{\partial v_i}&=-\sum_{j\neq i}A_{ij}v_j-\sum_{j\neq i}A_{ji}v_j-2A_{ii}v_i-\beta_i
\\&=-\sum_j(A_{ij}+A^T_{ij})v_j-\beta_i
\\ \Rightarrow \nabla H&=-(A+A^T)\vec{v}-\vec{\beta}
\\ \Rightarrow \nabla H\cdot \frac{d\vec{v}}{dt}&=-\vec{v}^T(A+A^T)A\vec{v}-\vec{v}^T(A+A^T)\vec{\beta}-\vec{\beta}^TA\vec{v}-\vec{\beta}^T\vec{\beta}
\\&=-\vec{v}^TA^2\vec{v}-\vec{v}^TA^TA\vec{v}-\vec{v}^TA\vec{\beta}-2\vec{v}^TA^T\vec{\beta}-\vec{\beta}^T\vec{\beta}
\end{align*}
If $A$ is negative semi-definite, then $A^2$ is positive semi-definite and $A^TA$ is positive semi-definite.  (Consider that $\vec{v}^TA^TA\vec{v}=(A\vec{v})^T(A\vec{v})$ so that $\vec{v}A^TA\vec{v}=0$ if $A\vec{v}=0$ and $\vec{v}^TA^TA\vec{v}<0$ otherwise.) Therefore, $-\vec{v}^TA^2\vec{v}\leq 0$ and $-\vec{v}^TA^TA\vec{v}\leq 0$. At equilibrium, $\vec{v}$ will be ``close" to $\vec{\beta}$ so that $$-\vec{v}^TA\vec{\beta}-2\vec{v}^TA^T\vec{\beta}\sim-\vec{\beta}^TA\vec{\beta}$$
\end{pf}

\subsection{Numerically evaluating dynamics }
\begin{claim}
Let $\Phi(t)$ be the fundamental matrix solution to the homogeneous differential equations $\frac{d\vec{x}}{dt}=A\vec{x}$ so that $\Phi(t)=V\Lambda(t)$ where the columns of $V$ are the eigenvectors of $A$ and $$\Lambda(t)=\text{diag}(e^{\lambda_1 t},\dots,e^{\lambda_n t})$$ where $\{\lambda_i\}$ are the eigenvalues of $A$.  (Note that if $\lambda_i=0$ then $e^{\lambda _i t}=1$ for all $t$.) Let $V^\dagger$ be the pseudoinverse of $V$.  Let $\vec{c}=V^\dagger\vec{X_0}$.  Let $$G(t)=\text{diag}(1/\lambda_1(1-e^{-\lambda_1t}),\dots,1/\lambda_n(1-e^{-\lambda_nt}))V^\dagger\vec{\beta}.$$
(If $\lambda_i=0$ then the corresponding entry of the first part of $G(t)$ will be given by $t$ rather than the form above.)  THEN if we let $x(t)=\Phi(t)G(t)+\Phi(t)\vec{c}$, $X(t)$ solves the inhomogeneous equations $\frac{dx}{dt}=A\vec{x}+\vec{\beta}$ with initial conditions $x(0)=\vec{X_0}$.
\end{claim}

\begin{pf}
It is clear that
\begin{align*}
\frac{d\Phi\vec{c}}{dt}&=A\Phi(t)\vec{c} \text{ and } \Phi(0)\vec{c}=\vec{X_0}.
\end{align*}
Now, 
\begin{align*}
\Phi(t)G(t)&=V
\left(\begin{array}{ccccc}
e^{\lambda_1 t}  &\dots &0
\\ \vdots & \ddots &\vdots
\\ 0 & \dots & e^{\lambda_nt}
 \end{array}\right)
 \left(\begin{array}{ccccc}
\frac{1}{\lambda_1}(1-e^{\lambda_1 t})  &\dots &0
\\ \vdots & \ddots &\vdots
\\ 0 & \dots &\frac{1}{\lambda_n} (1-e^{\lambda_nt})
 \end{array}\right)
 V^\dagger\vec{\beta}
 \\&=V
 \left(\begin{array}{ccccc}
\frac{1}{\lambda_1}(e^{\lambda_1 t}-1)  &\dots &0
\\ \vdots & \ddots &\vdots
\\ 0 & \dots &\frac{1}{\lambda_n} (e^{\lambda_nt}-1)
 \end{array}\right)
 V^\dagger\vec{\beta}
 \\ \Rightarrow \frac{d\Phi(t)G(t)}{dt}&=V
 \left(\begin{array}{ccccc}
e^{\lambda_1 t}  &\dots &0
\\ \vdots & \ddots &\vdots
\\ 0 & \dots &e^{\lambda_nt}
 \end{array}\right)
 \\&=V
 \left(\begin{array}{ccccc}
e^{\lambda_1 t}  &\dots &0
\\ \vdots & \ddots &\vdots
\\ 0 & \dots &e^{\lambda_nt}
 \end{array}\right)
 V^\dagger\vec{\beta} -VV^\dagger\vec{\beta}+\vec{\beta}
 \\&=V
 \left(\begin{array}{ccccc}
e^{\lambda_1 t}-1  &\dots &0
\\ \vdots & \ddots &\vdots
\\ 0 & \dots &e^{\lambda_nt}-1
 \end{array}\right)
 V^\dagger\vec{\beta} +\vec{\beta}
  \\&=V
 \left(\begin{array}{ccccc}
\lambda_1e^{\lambda_1t}\cdot \frac{1}{\lambda_1}(1-e^{-\lambda_1 t})  &\dots &0
\\ \vdots & \ddots &\vdots
\\ 0 & \dots &\lambda_ne^{\lambda_nt}\cdot\frac{1}{\lambda_n}(1-e^{-\lambda_nt})
 \end{array}\right)
 V^\dagger\vec{\beta} +\vec{\beta}
  \\&=AV\Lambda(t)
 \left(\begin{array}{ccccc}
 \frac{1}{\lambda_1}(1-e^{-\lambda_1 t})  &\dots &0
\\ \vdots & \ddots &\vdots
\\ 0 & \dots &\frac{1}{\lambda_n}(1-e^{-\lambda_nt})
 \end{array}\right)
 V^\dagger\vec{\beta} +\vec{\beta}
 \\&=AV\Lambda(t)G(t)+\vec{\beta}
 \\&=A\Phi(t)G(t)+\vec{\beta}
\end{align*}
Therefore $\frac{dx}{dt}=A\Phi(t)G(t)+A\Phi(t)\vec{c}+\vec{\beta}=Ax(t)+\vec{\beta}$ and since $G(0)=\vec{0}$, $x(0)=\vec{X_0}$.
\end{pf}

\nocite{*}
\bibliographystyle{plain}
\bibliography{info_evo}

\end{document}


